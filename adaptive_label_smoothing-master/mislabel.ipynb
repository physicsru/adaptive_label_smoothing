{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from net import Net\n",
    "import random\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zliu/anaconda3/envs/myenv/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(args, model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    acc = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    acc=100. * correct / len(test_loader.dataset);\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        acc))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zliu/anaconda3/envs/myenv/lib/python3.6/site-packages/torchvision/datasets/mnist.py:43: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4,  ..., 5, 6, 8])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ran=[i for i in range(0,60000)]\n",
    "random.seed(42)\n",
    "index=random.sample(ran,int(60000*0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_origin=copy.deepcopy(x.train_labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 5, 6,  ..., 5, 5, 9])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.train_labels[index]=x.train_labels[index].random_(0,10)\n",
    "x.train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16778"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_origin==x.train_labels.numpy()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Training settings\n",
    "    parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "    parser.add_argument('--batch-size', type=int, default=512, metavar='N',\n",
    "                        help='input batch size for training (default: 256)')\n",
    "    parser.add_argument('--test-batch-size', type=int, default=4000, metavar='N',\n",
    "                        help='input batch size for testing (default: 1000)')\n",
    "    parser.add_argument('--epochs', type=int, default=100, metavar='N',\n",
    "                        help='number of epochs to train (default: 10)')\n",
    "    parser.add_argument('--lr', type=float, default=0.005, metavar='LR',\n",
    "                        help='learning rate (default: 0.01)')\n",
    "    parser.add_argument('--momentum', type=float, default=0.9, metavar='M',\n",
    "                        help='SGD momentum (default: 0.5)')\n",
    "    parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                        help='disables CUDA training')\n",
    "    parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                        help='random seed (default: 1)')\n",
    "    parser.add_argument('--log-interval', type=int, default=100, metavar='N',\n",
    "                        help='how many batches to wait before logging training status')\n",
    "    \n",
    "    parser.add_argument('--save-model', action='store_true', default=False,\n",
    "                        help='For Saving the current Model')\n",
    "    args = parser.parse_args()\n",
    "    use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "     \n",
    "    kwargs = {'num_workers': 4, 'pin_memory': True} if use_cuda else {}\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        x,\n",
    "        batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=args.test_batch_size, shuffle=True, **kwargs)\n",
    "#     train_loader=x\n",
    "\n",
    "    model = Net().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "\n",
    "    acc=[]\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "        acc.append(test(args, model, device, test_loader))\n",
    "    np.save(\"acc.npy\",acc)\n",
    "    if (args.save_model):\n",
    "        torch.save(model.state_dict(),\"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.309244\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.257778\n",
      "\n",
      "Test set: Average loss: 1.8728, Accuracy: 7379/10000 (74%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.248241\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 2.226424\n",
      "\n",
      "Test set: Average loss: 1.6833, Accuracy: 8588/10000 (86%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 2.189944\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 2.184569\n",
      "\n",
      "Test set: Average loss: 1.5941, Accuracy: 8963/10000 (90%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 2.208335\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 2.209778\n",
      "\n",
      "Test set: Average loss: 1.5597, Accuracy: 9046/10000 (90%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 2.245119\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 2.223413\n",
      "\n",
      "Test set: Average loss: 1.5389, Accuracy: 9164/10000 (92%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 2.209274\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 2.220912\n",
      "\n",
      "Test set: Average loss: 1.5266, Accuracy: 9286/10000 (93%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 2.182313\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 2.180693\n",
      "\n",
      "Test set: Average loss: 1.4775, Accuracy: 9413/10000 (94%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 2.182739\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 2.195881\n",
      "\n",
      "Test set: Average loss: 1.4831, Accuracy: 9446/10000 (94%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 2.186544\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 2.207423\n",
      "\n",
      "Test set: Average loss: 1.4279, Accuracy: 9471/10000 (95%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 2.169446\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 2.203688\n",
      "\n",
      "Test set: Average loss: 1.4210, Accuracy: 9518/10000 (95%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 2.201330\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 2.148304\n",
      "\n",
      "Test set: Average loss: 1.4480, Accuracy: 9542/10000 (95%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 2.142323\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 2.208432\n",
      "\n",
      "Test set: Average loss: 1.4122, Accuracy: 9570/10000 (96%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 2.210439\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 2.164778\n",
      "\n",
      "Test set: Average loss: 1.4101, Accuracy: 9553/10000 (96%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 2.196728\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 2.185279\n",
      "\n",
      "Test set: Average loss: 1.3923, Accuracy: 9599/10000 (96%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 2.164371\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 2.178921\n",
      "\n",
      "Test set: Average loss: 1.4289, Accuracy: 9600/10000 (96%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 2.153501\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 2.195961\n",
      "\n",
      "Test set: Average loss: 1.4196, Accuracy: 9633/10000 (96%)\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 2.182773\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 2.219911\n",
      "\n",
      "Test set: Average loss: 1.4190, Accuracy: 9597/10000 (96%)\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 2.175317\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 2.153762\n",
      "\n",
      "Test set: Average loss: 1.3949, Accuracy: 9611/10000 (96%)\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 2.178456\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 2.135571\n",
      "\n",
      "Test set: Average loss: 1.3616, Accuracy: 9659/10000 (97%)\n",
      "\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 2.230777\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 2.180997\n",
      "\n",
      "Test set: Average loss: 1.3592, Accuracy: 9652/10000 (97%)\n",
      "\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 2.104954\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 2.163034\n",
      "\n",
      "Test set: Average loss: 1.3920, Accuracy: 9576/10000 (96%)\n",
      "\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 2.132157\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 2.179927\n",
      "\n",
      "Test set: Average loss: 1.3721, Accuracy: 9634/10000 (96%)\n",
      "\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 2.154786\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 2.191993\n",
      "\n",
      "Test set: Average loss: 1.3531, Accuracy: 9626/10000 (96%)\n",
      "\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 2.114714\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 2.200160\n",
      "\n",
      "Test set: Average loss: 1.3686, Accuracy: 9624/10000 (96%)\n",
      "\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 2.119028\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 2.113867\n",
      "\n",
      "Test set: Average loss: 1.3625, Accuracy: 9585/10000 (96%)\n",
      "\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 2.114533\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 2.132077\n",
      "\n",
      "Test set: Average loss: 1.3950, Accuracy: 9624/10000 (96%)\n",
      "\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 2.170130\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 2.173588\n",
      "\n",
      "Test set: Average loss: 1.3787, Accuracy: 9570/10000 (96%)\n",
      "\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 2.201191\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 2.157892\n",
      "\n",
      "Test set: Average loss: 1.4103, Accuracy: 9213/10000 (92%)\n",
      "\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 2.124084\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 2.139664\n",
      "\n",
      "Test set: Average loss: 1.3647, Accuracy: 9599/10000 (96%)\n",
      "\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 2.124234\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 2.125112\n",
      "\n",
      "Test set: Average loss: 1.3944, Accuracy: 9516/10000 (95%)\n",
      "\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 2.099935\n",
      "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 2.132261\n",
      "\n",
      "Test set: Average loss: 1.3371, Accuracy: 9569/10000 (96%)\n",
      "\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 2.166149\n",
      "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 2.143617\n",
      "\n",
      "Test set: Average loss: 1.3914, Accuracy: 9427/10000 (94%)\n",
      "\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 2.140495\n",
      "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 2.147352\n",
      "\n",
      "Test set: Average loss: 1.3726, Accuracy: 9467/10000 (95%)\n",
      "\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 2.112705\n",
      "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 2.121732\n",
      "\n",
      "Test set: Average loss: 1.3822, Accuracy: 9492/10000 (95%)\n",
      "\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 2.133266\n",
      "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 2.126227\n",
      "\n",
      "Test set: Average loss: 1.3408, Accuracy: 9403/10000 (94%)\n",
      "\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 2.091118\n",
      "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 2.156117\n",
      "\n",
      "Test set: Average loss: 1.3774, Accuracy: 9336/10000 (93%)\n",
      "\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 2.121814\n",
      "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 2.124692\n",
      "\n",
      "Test set: Average loss: 1.3706, Accuracy: 9302/10000 (93%)\n",
      "\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 2.101512\n",
      "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 2.081596\n",
      "\n",
      "Test set: Average loss: 1.3530, Accuracy: 9139/10000 (91%)\n",
      "\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 2.081727\n",
      "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 2.121265\n",
      "\n",
      "Test set: Average loss: 1.4415, Accuracy: 9119/10000 (91%)\n",
      "\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 2.107253\n",
      "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 2.137708\n",
      "\n",
      "Test set: Average loss: 1.3313, Accuracy: 9007/10000 (90%)\n",
      "\n",
      "Train Epoch: 41 [0/60000 (0%)]\tLoss: 2.094519\n",
      "Train Epoch: 41 [51200/60000 (85%)]\tLoss: 2.030903\n",
      "\n",
      "Test set: Average loss: 1.3038, Accuracy: 9137/10000 (91%)\n",
      "\n",
      "Train Epoch: 42 [0/60000 (0%)]\tLoss: 2.087712\n",
      "Train Epoch: 42 [51200/60000 (85%)]\tLoss: 2.104910\n",
      "\n",
      "Test set: Average loss: 1.3475, Accuracy: 8958/10000 (90%)\n",
      "\n",
      "Train Epoch: 43 [0/60000 (0%)]\tLoss: 2.100993\n",
      "Train Epoch: 43 [51200/60000 (85%)]\tLoss: 2.087851\n",
      "\n",
      "Test set: Average loss: 1.3416, Accuracy: 9065/10000 (91%)\n",
      "\n",
      "Train Epoch: 44 [0/60000 (0%)]\tLoss: 2.035936\n",
      "Train Epoch: 44 [51200/60000 (85%)]\tLoss: 2.063556\n",
      "\n",
      "Test set: Average loss: 1.3469, Accuracy: 8742/10000 (87%)\n",
      "\n",
      "Train Epoch: 45 [0/60000 (0%)]\tLoss: 2.089203\n",
      "Train Epoch: 45 [51200/60000 (85%)]\tLoss: 2.113186\n",
      "\n",
      "Test set: Average loss: 1.3149, Accuracy: 8825/10000 (88%)\n",
      "\n",
      "Train Epoch: 46 [0/60000 (0%)]\tLoss: 2.041299\n",
      "Train Epoch: 46 [51200/60000 (85%)]\tLoss: 2.102845\n",
      "\n",
      "Test set: Average loss: 1.4150, Accuracy: 8489/10000 (85%)\n",
      "\n",
      "Train Epoch: 47 [0/60000 (0%)]\tLoss: 2.050847\n",
      "Train Epoch: 47 [51200/60000 (85%)]\tLoss: 2.058706\n",
      "\n",
      "Test set: Average loss: 1.3780, Accuracy: 8367/10000 (84%)\n",
      "\n",
      "Train Epoch: 48 [0/60000 (0%)]\tLoss: 2.021457\n",
      "Train Epoch: 48 [51200/60000 (85%)]\tLoss: 2.049684\n",
      "\n",
      "Test set: Average loss: 1.3918, Accuracy: 8281/10000 (83%)\n",
      "\n",
      "Train Epoch: 49 [0/60000 (0%)]\tLoss: 2.079636\n",
      "Train Epoch: 49 [51200/60000 (85%)]\tLoss: 2.058402\n",
      "\n",
      "Test set: Average loss: 1.4024, Accuracy: 8128/10000 (81%)\n",
      "\n",
      "Train Epoch: 50 [0/60000 (0%)]\tLoss: 2.056148\n",
      "Train Epoch: 50 [51200/60000 (85%)]\tLoss: 2.016411\n",
      "\n",
      "Test set: Average loss: 1.4074, Accuracy: 7792/10000 (78%)\n",
      "\n",
      "Train Epoch: 51 [0/60000 (0%)]\tLoss: 2.038814\n",
      "Train Epoch: 51 [51200/60000 (85%)]\tLoss: 2.052953\n",
      "\n",
      "Test set: Average loss: 1.3769, Accuracy: 8226/10000 (82%)\n",
      "\n",
      "Train Epoch: 52 [0/60000 (0%)]\tLoss: 2.006431\n",
      "Train Epoch: 52 [51200/60000 (85%)]\tLoss: 2.038190\n",
      "\n",
      "Test set: Average loss: 1.3199, Accuracy: 8016/10000 (80%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 53 [0/60000 (0%)]\tLoss: 2.031003\n",
      "Train Epoch: 53 [51200/60000 (85%)]\tLoss: 2.063035\n",
      "\n",
      "Test set: Average loss: 1.4298, Accuracy: 7596/10000 (76%)\n",
      "\n",
      "Train Epoch: 54 [0/60000 (0%)]\tLoss: 1.979268\n",
      "Train Epoch: 54 [51200/60000 (85%)]\tLoss: 2.030001\n",
      "\n",
      "Test set: Average loss: 1.4762, Accuracy: 6496/10000 (65%)\n",
      "\n",
      "Train Epoch: 55 [0/60000 (0%)]\tLoss: 1.992320\n",
      "Train Epoch: 55 [51200/60000 (85%)]\tLoss: 2.036643\n",
      "\n",
      "Test set: Average loss: 1.3851, Accuracy: 7187/10000 (72%)\n",
      "\n",
      "Train Epoch: 56 [0/60000 (0%)]\tLoss: 1.958274\n",
      "Train Epoch: 56 [51200/60000 (85%)]\tLoss: 2.003374\n",
      "\n",
      "Test set: Average loss: 1.4444, Accuracy: 7355/10000 (74%)\n",
      "\n",
      "Train Epoch: 57 [0/60000 (0%)]\tLoss: 1.904207\n",
      "Train Epoch: 57 [51200/60000 (85%)]\tLoss: 1.982331\n",
      "\n",
      "Test set: Average loss: 1.4358, Accuracy: 7063/10000 (71%)\n",
      "\n",
      "Train Epoch: 58 [0/60000 (0%)]\tLoss: 1.927416\n",
      "Train Epoch: 58 [51200/60000 (85%)]\tLoss: 2.023820\n",
      "\n",
      "Test set: Average loss: 1.5599, Accuracy: 6216/10000 (62%)\n",
      "\n",
      "Train Epoch: 59 [0/60000 (0%)]\tLoss: 1.988510\n",
      "Train Epoch: 59 [51200/60000 (85%)]\tLoss: 2.040807\n",
      "\n",
      "Test set: Average loss: 1.3973, Accuracy: 7024/10000 (70%)\n",
      "\n",
      "Train Epoch: 60 [0/60000 (0%)]\tLoss: 1.942730\n",
      "Train Epoch: 60 [51200/60000 (85%)]\tLoss: 1.993114\n",
      "\n",
      "Test set: Average loss: 1.4278, Accuracy: 6971/10000 (70%)\n",
      "\n",
      "Train Epoch: 61 [0/60000 (0%)]\tLoss: 1.928864\n",
      "Train Epoch: 61 [51200/60000 (85%)]\tLoss: 2.036811\n",
      "\n",
      "Test set: Average loss: 1.4491, Accuracy: 6536/10000 (65%)\n",
      "\n",
      "Train Epoch: 62 [0/60000 (0%)]\tLoss: 1.932453\n",
      "Train Epoch: 62 [51200/60000 (85%)]\tLoss: 1.974472\n",
      "\n",
      "Test set: Average loss: 1.5307, Accuracy: 5971/10000 (60%)\n",
      "\n",
      "Train Epoch: 63 [0/60000 (0%)]\tLoss: 1.889022\n",
      "Train Epoch: 63 [51200/60000 (85%)]\tLoss: 1.893307\n",
      "\n",
      "Test set: Average loss: 1.4894, Accuracy: 6004/10000 (60%)\n",
      "\n",
      "Train Epoch: 64 [0/60000 (0%)]\tLoss: 1.901808\n",
      "Train Epoch: 64 [51200/60000 (85%)]\tLoss: 1.931891\n",
      "\n",
      "Test set: Average loss: 1.4625, Accuracy: 6185/10000 (62%)\n",
      "\n",
      "Train Epoch: 65 [0/60000 (0%)]\tLoss: 1.918139\n",
      "Train Epoch: 65 [51200/60000 (85%)]\tLoss: 1.912130\n",
      "\n",
      "Test set: Average loss: 1.4091, Accuracy: 6169/10000 (62%)\n",
      "\n",
      "Train Epoch: 66 [0/60000 (0%)]\tLoss: 1.963094\n",
      "Train Epoch: 66 [51200/60000 (85%)]\tLoss: 1.948313\n",
      "\n",
      "Test set: Average loss: 1.4487, Accuracy: 6042/10000 (60%)\n",
      "\n",
      "Train Epoch: 67 [0/60000 (0%)]\tLoss: 1.869224\n",
      "Train Epoch: 67 [51200/60000 (85%)]\tLoss: 1.902788\n",
      "\n",
      "Test set: Average loss: 1.3623, Accuracy: 6515/10000 (65%)\n",
      "\n",
      "Train Epoch: 68 [0/60000 (0%)]\tLoss: 1.846423\n",
      "Train Epoch: 68 [51200/60000 (85%)]\tLoss: 1.861975\n",
      "\n",
      "Test set: Average loss: 1.5114, Accuracy: 5752/10000 (58%)\n",
      "\n",
      "Train Epoch: 69 [0/60000 (0%)]\tLoss: 1.802173\n",
      "Train Epoch: 69 [51200/60000 (85%)]\tLoss: 1.882919\n",
      "\n",
      "Test set: Average loss: 1.4938, Accuracy: 5765/10000 (58%)\n",
      "\n",
      "Train Epoch: 70 [0/60000 (0%)]\tLoss: 1.801681\n",
      "Train Epoch: 70 [51200/60000 (85%)]\tLoss: 1.862746\n",
      "\n",
      "Test set: Average loss: 1.4921, Accuracy: 5625/10000 (56%)\n",
      "\n",
      "Train Epoch: 71 [0/60000 (0%)]\tLoss: 1.831148\n",
      "Train Epoch: 71 [51200/60000 (85%)]\tLoss: 1.763656\n",
      "\n",
      "Test set: Average loss: 1.5669, Accuracy: 5099/10000 (51%)\n",
      "\n",
      "Train Epoch: 72 [0/60000 (0%)]\tLoss: 1.713801\n",
      "Train Epoch: 72 [51200/60000 (85%)]\tLoss: 1.835804\n",
      "\n",
      "Test set: Average loss: 1.5427, Accuracy: 5067/10000 (51%)\n",
      "\n",
      "Train Epoch: 73 [0/60000 (0%)]\tLoss: 1.827456\n",
      "Train Epoch: 73 [51200/60000 (85%)]\tLoss: 1.788777\n",
      "\n",
      "Test set: Average loss: 1.6417, Accuracy: 4694/10000 (47%)\n",
      "\n",
      "Train Epoch: 74 [0/60000 (0%)]\tLoss: 1.678273\n",
      "Train Epoch: 74 [51200/60000 (85%)]\tLoss: 1.802964\n",
      "\n",
      "Test set: Average loss: 1.5406, Accuracy: 5286/10000 (53%)\n",
      "\n",
      "Train Epoch: 75 [0/60000 (0%)]\tLoss: 1.671993\n",
      "Train Epoch: 75 [51200/60000 (85%)]\tLoss: 1.685024\n",
      "\n",
      "Test set: Average loss: 1.4813, Accuracy: 5444/10000 (54%)\n",
      "\n",
      "Train Epoch: 76 [0/60000 (0%)]\tLoss: 1.786797\n",
      "Train Epoch: 76 [51200/60000 (85%)]\tLoss: 1.826429\n",
      "\n",
      "Test set: Average loss: 1.6347, Accuracy: 4494/10000 (45%)\n",
      "\n",
      "Train Epoch: 77 [0/60000 (0%)]\tLoss: 1.715406\n",
      "Train Epoch: 77 [51200/60000 (85%)]\tLoss: 1.714025\n",
      "\n",
      "Test set: Average loss: 1.5661, Accuracy: 4817/10000 (48%)\n",
      "\n",
      "Train Epoch: 78 [0/60000 (0%)]\tLoss: 1.695613\n",
      "Train Epoch: 78 [51200/60000 (85%)]\tLoss: 1.643378\n",
      "\n",
      "Test set: Average loss: 1.6986, Accuracy: 4348/10000 (43%)\n",
      "\n",
      "Train Epoch: 79 [0/60000 (0%)]\tLoss: 1.678766\n",
      "Train Epoch: 79 [51200/60000 (85%)]\tLoss: 1.766344\n",
      "\n",
      "Test set: Average loss: 1.5907, Accuracy: 4785/10000 (48%)\n",
      "\n",
      "Train Epoch: 80 [0/60000 (0%)]\tLoss: 1.568757\n",
      "Train Epoch: 80 [51200/60000 (85%)]\tLoss: 1.674220\n",
      "\n",
      "Test set: Average loss: 1.6807, Accuracy: 4263/10000 (43%)\n",
      "\n",
      "Train Epoch: 81 [0/60000 (0%)]\tLoss: 1.607919\n",
      "Train Epoch: 81 [51200/60000 (85%)]\tLoss: 1.731211\n",
      "\n",
      "Test set: Average loss: 1.7174, Accuracy: 4183/10000 (42%)\n",
      "\n",
      "Train Epoch: 82 [0/60000 (0%)]\tLoss: 1.531229\n",
      "Train Epoch: 82 [51200/60000 (85%)]\tLoss: 1.597852\n",
      "\n",
      "Test set: Average loss: 1.6448, Accuracy: 4712/10000 (47%)\n",
      "\n",
      "Train Epoch: 83 [0/60000 (0%)]\tLoss: 1.616049\n",
      "Train Epoch: 83 [51200/60000 (85%)]\tLoss: 1.656138\n",
      "\n",
      "Test set: Average loss: 1.7032, Accuracy: 4361/10000 (44%)\n",
      "\n",
      "Train Epoch: 84 [0/60000 (0%)]\tLoss: 1.527979\n",
      "Train Epoch: 84 [51200/60000 (85%)]\tLoss: 1.627266\n",
      "\n",
      "Test set: Average loss: 1.6541, Accuracy: 4104/10000 (41%)\n",
      "\n",
      "Train Epoch: 85 [0/60000 (0%)]\tLoss: 1.599291\n",
      "Train Epoch: 85 [51200/60000 (85%)]\tLoss: 1.553883\n",
      "\n",
      "Test set: Average loss: 1.7970, Accuracy: 3982/10000 (40%)\n",
      "\n",
      "Train Epoch: 86 [0/60000 (0%)]\tLoss: 1.524779\n",
      "Train Epoch: 86 [51200/60000 (85%)]\tLoss: 1.520543\n",
      "\n",
      "Test set: Average loss: 1.6912, Accuracy: 4183/10000 (42%)\n",
      "\n",
      "Train Epoch: 87 [0/60000 (0%)]\tLoss: 1.403032\n",
      "Train Epoch: 87 [51200/60000 (85%)]\tLoss: 1.485785\n",
      "\n",
      "Test set: Average loss: 1.7868, Accuracy: 3929/10000 (39%)\n",
      "\n",
      "Train Epoch: 88 [0/60000 (0%)]\tLoss: 1.367321\n",
      "Train Epoch: 88 [51200/60000 (85%)]\tLoss: 1.486146\n",
      "\n",
      "Test set: Average loss: 1.7091, Accuracy: 4145/10000 (41%)\n",
      "\n",
      "Train Epoch: 89 [0/60000 (0%)]\tLoss: 1.469277\n",
      "Train Epoch: 89 [51200/60000 (85%)]\tLoss: 1.461473\n",
      "\n",
      "Test set: Average loss: 2.0398, Accuracy: 3000/10000 (30%)\n",
      "\n",
      "Train Epoch: 90 [0/60000 (0%)]\tLoss: 1.484329\n",
      "Train Epoch: 90 [51200/60000 (85%)]\tLoss: 1.496483\n",
      "\n",
      "Test set: Average loss: 1.8832, Accuracy: 3546/10000 (35%)\n",
      "\n",
      "Train Epoch: 91 [0/60000 (0%)]\tLoss: 1.266471\n",
      "Train Epoch: 91 [51200/60000 (85%)]\tLoss: 1.412429\n",
      "\n",
      "Test set: Average loss: 2.1336, Accuracy: 3121/10000 (31%)\n",
      "\n",
      "Train Epoch: 92 [0/60000 (0%)]\tLoss: 1.387386\n",
      "Train Epoch: 92 [51200/60000 (85%)]\tLoss: 1.394294\n",
      "\n",
      "Test set: Average loss: 1.9221, Accuracy: 3425/10000 (34%)\n",
      "\n",
      "Train Epoch: 93 [0/60000 (0%)]\tLoss: 1.205582\n",
      "Train Epoch: 93 [51200/60000 (85%)]\tLoss: 1.461128\n",
      "\n",
      "Test set: Average loss: 1.8767, Accuracy: 3717/10000 (37%)\n",
      "\n",
      "Train Epoch: 94 [0/60000 (0%)]\tLoss: 1.376436\n",
      "Train Epoch: 94 [51200/60000 (85%)]\tLoss: 1.362304\n",
      "\n",
      "Test set: Average loss: 1.9298, Accuracy: 3912/10000 (39%)\n",
      "\n",
      "Train Epoch: 95 [0/60000 (0%)]\tLoss: 1.280180\n",
      "Train Epoch: 95 [51200/60000 (85%)]\tLoss: 1.373256\n",
      "\n",
      "Test set: Average loss: 1.9186, Accuracy: 3849/10000 (38%)\n",
      "\n",
      "Train Epoch: 96 [0/60000 (0%)]\tLoss: 1.238497\n",
      "Train Epoch: 96 [51200/60000 (85%)]\tLoss: 1.276203\n",
      "\n",
      "Test set: Average loss: 1.9095, Accuracy: 4096/10000 (41%)\n",
      "\n",
      "Train Epoch: 97 [0/60000 (0%)]\tLoss: 1.263538\n",
      "Train Epoch: 97 [51200/60000 (85%)]\tLoss: 1.260453\n",
      "\n",
      "Test set: Average loss: 2.2342, Accuracy: 2803/10000 (28%)\n",
      "\n",
      "Train Epoch: 98 [0/60000 (0%)]\tLoss: 1.247884\n",
      "Train Epoch: 98 [51200/60000 (85%)]\tLoss: 1.308526\n",
      "\n",
      "Test set: Average loss: 2.0503, Accuracy: 3637/10000 (36%)\n",
      "\n",
      "Train Epoch: 99 [0/60000 (0%)]\tLoss: 1.162154\n",
      "Train Epoch: 99 [51200/60000 (85%)]\tLoss: 1.195295\n",
      "\n",
      "Test set: Average loss: 2.0566, Accuracy: 3539/10000 (35%)\n",
      "\n",
      "Train Epoch: 100 [0/60000 (0%)]\tLoss: 1.172913\n",
      "Train Epoch: 100 [51200/60000 (85%)]\tLoss: 1.244249\n",
      "\n",
      "Test set: Average loss: 2.0792, Accuracy: 3754/10000 (38%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sys.argv = ['-f']\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([44.91, 60.23, 70.1 , 76.84, 81.74])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=np.load(\"acc.npy\")\n",
    "x_axis=np.arange(100)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (100,) and (5,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f2f115771ca5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_axis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2793\u001b[0m     return gca().plot(\n\u001b[1;32m   2794\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2795\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1664\u001b[0m         \"\"\"\n\u001b[1;32m   1665\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1666\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1667\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 270\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (100,) and (5,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_axis,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tor",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
