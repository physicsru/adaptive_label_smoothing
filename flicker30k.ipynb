{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datetime import datetime\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "#from model import IDCM_NN\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgNN(nn.Module):\n",
    "    \"\"\"Network to learn image representations\"\"\"\n",
    "    def __init__(self, input_dim=4096, output_dim=1024):\n",
    "        super(ImgNN, self).__init__()\n",
    "        self.denseL1 = nn.Linear(input_dim, 1024)\n",
    "        self.denseL2 = nn.Linear(1024, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(x)\n",
    "        out = F.relu(self.denseL1(x))\n",
    "        out = F.relu(self.denseL2(out))\n",
    "        return out\n",
    "\n",
    "\n",
    "class TextNN(nn.Module):\n",
    "    \"\"\"Network to learn text representations\"\"\"\n",
    "    def __init__(self, input_dim=1024, output_dim=1024):\n",
    "        super(TextNN, self).__init__()\n",
    "        self.denseL1 = nn.Linear(input_dim, output_dim)\n",
    "        self.denseL2 = nn.Linear(output_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.denseL1(x))\n",
    "        out = F.relu(self.denseL2(out))\n",
    "        return out\n",
    "\n",
    "\n",
    "class IDCM_NN(nn.Module):\n",
    "    \"\"\"Network to learn text representations\"\"\"\n",
    "    def __init__(self, img_input_dim=4096, img_output_dim=2048,\n",
    "                 text_input_dim=1024, text_output_dim=2048, minus_one_dim=1024, output_dim=10):\n",
    "        super(IDCM_NN, self).__init__()\n",
    "        self.img_net = ImgNN(img_input_dim, img_output_dim)\n",
    "        self.text_net = TextNN(text_input_dim, text_output_dim)\n",
    "        self.linearLayer = nn.Linear(img_output_dim, minus_one_dim)\n",
    "        #self.linearLayer2 = nn.Linear(minus_one_dim, output_dim)\n",
    "\n",
    "    def forward(self, img, text):\n",
    "        view1_feature = self.img_net(img)\n",
    "        view2_feature = self.text_net(text)\n",
    "        view1_feature = self.linearLayer(view1_feature)\n",
    "        view2_feature = self.linearLayer(view2_feature)\n",
    "\n",
    "        view1_predict = view1_feature#self.linearLayer2((view1_feature))\n",
    "        view2_predict = view2_feature#self.linearLayer2((view2_feature))\n",
    "        return view1_feature, view2_feature, view1_predict, view2_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "from scipy.io import loadmat, savemat\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class CustomDataSet(Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            images,\n",
    "            texts,\n",
    "            labels):\n",
    "        self.images = np.array(images, dtype=np.float32)\n",
    "        self.texts = np.array(texts, dtype=np.float32)\n",
    "        self.labels = np.array(labels, dtype=np.int)\n",
    "        self.labels = np.squeeze(self.labels)\n",
    "        #print(type(self.images), type(self.texts), type(self.labels))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.images[index]\n",
    "        text = self.texts[index]\n",
    "        label = self.labels[index]\n",
    "        return img, text, label\n",
    "\n",
    "    def __len__(self):\n",
    "        count = len(self.images)\n",
    "        #print(len(self.images),len(self.labels))\n",
    "        assert len(self.images) == len(self.labels)\n",
    "        return count\n",
    "\n",
    "\n",
    "def ind2vec(ind, N=None):\n",
    "    ind = np.asarray(ind)\n",
    "    if N is None:\n",
    "        N = ind.max() + 1\n",
    "    return np.arange(N) == np.repeat(ind, N, axis=1)\n",
    "\n",
    "def get_loader(path, batch_size):\n",
    "    img_train = loadmat(path+\"train_img.mat\")['train_img'].astype(float)\n",
    "    img_test = loadmat(path + \"test_img.mat\")['test_img'].astype(float)\n",
    "    text_train = loadmat(path+\"train_txt.mat\")['train_txt'].astype(float)\n",
    "    text_test = loadmat(path + \"test_txt.mat\")['test_txt'].astype(float)\n",
    "    label_train = loadmat(path+\"train_img_lab.mat\")['train_img_lab'].astype(int)\n",
    "    label_test = loadmat(path + \"test_img_lab.mat\")['test_img_lab'].astype(int)\n",
    "    print(label_train)\n",
    "    #print(\"shapes are:  \", img_train.shape, img_test.shape, text_train.shape, text_test.shape, label_train.shape, label_test.shape)\n",
    "    #label_train = label_train.reshape(label_train.shape[1])\n",
    "    #label_test = label_test.reshape(label_test.shape[1])\n",
    "\n",
    "    #label_train = ind2vec(label_train).astype(int)\n",
    "    #label_test = ind2vec(label_test).astype(int)\n",
    "\n",
    "    imgs = {'train': img_train, 'test': img_test}\n",
    "    texts = {'train': text_train, 'test': text_test}\n",
    "    labels = {'train': label_train, 'test': label_test}\n",
    "    dataset = {x: CustomDataSet(images=imgs[x], texts=texts[x], labels=labels[x])\n",
    "               for x in ['train', 'test']}\n",
    "\n",
    "    shuffle = {'train': False, 'test': False}\n",
    "\n",
    "    dataloader = {x: DataLoader(dataset[x], batch_size=batch_size,\n",
    "                                shuffle=shuffle[x], num_workers=0) for x in ['train', 'test']}\n",
    "\n",
    "    img_dim = img_train.shape[1]\n",
    "    text_dim = text_train.shape[1]\n",
    "    num_class = label_train.shape[1]\n",
    "\n",
    "    input_data_par = {}\n",
    "    input_data_par['img_test'] = img_test\n",
    "    input_data_par['text_test'] = text_test\n",
    "    input_data_par['label_test'] = label_test\n",
    "    input_data_par['img_train'] = img_train\n",
    "    input_data_par['text_train'] = text_train\n",
    "    input_data_par['label_train'] = label_train\n",
    "    input_data_par['img_dim'] = img_dim\n",
    "    input_data_par['text_dim'] = text_dim\n",
    "    input_data_par['num_class'] = num_class\n",
    "    return dataloader, input_data_par\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.6.0\n",
      "Torchvision Version:  0.7.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import time\n",
    "import copy\n",
    "from evaluate import fx_calc_map_label\n",
    "import torch.nn.functional as F\n",
    "from evaluate import fx_calc_map_label\n",
    "import numpy as np\n",
    "print(\"PyTorch Version: \", torch.__version__)\n",
    "print(\"Torchvision Version: \", torchvision.__version__)\n",
    "\n",
    "\n",
    "def calc_label_sim(label_1, label_2):\n",
    "    Sim = label_1.float().mm(label_2.float().t())\n",
    "    return Sim\n",
    "\n",
    "# def cos(x, y):\n",
    "#     return x.mm(y.t())\n",
    "\n",
    "def calc_loss(view1_feature, view2_feature, view1_predict, view2_predict, labels_1, labels_2, alpha, beta):\n",
    "    term1 = ((view1_predict-labels_1.float())**2).sum(1).sqrt().mean() + ((view2_predict-labels_2.float())**2).sum(1).sqrt().mean()\n",
    "\n",
    "    cos = lambda x, y: x.mm(y.t()) / ((x ** 2).sum(1, keepdim=True).sqrt().mm((y ** 2).sum(1, keepdim=True).sqrt().t())).clamp(min=1e-6) / 2.\n",
    "    theta11 = cos(view1_feature, view1_feature)\n",
    "    theta12 = cos(view1_feature, view2_feature)\n",
    "    theta22 = cos(view2_feature, view2_feature)\n",
    "    Sim11 = calc_label_sim(labels_1, labels_1).float()\n",
    "    Sim12 = calc_label_sim(labels_1, labels_2).float()\n",
    "    Sim22 = calc_label_sim(labels_2, labels_2).float()\n",
    "    term21 = ((1+torch.exp(theta11)).log() - Sim11 * theta11).mean()\n",
    "    term22 = ((1+torch.exp(theta12)).log() - Sim12 * theta12).mean()\n",
    "    term23 = ((1 + torch.exp(theta22)).log() - Sim22 * theta22).mean()\n",
    "    term2 = term21 + term22 + term23\n",
    "\n",
    "    term3 = ((view1_feature - view2_feature)**2).sum(1).sqrt().mean()\n",
    "\n",
    "    im_loss = term1 + alpha * term2 + beta * term3\n",
    "    return im_loss\n",
    "\n",
    "def normalize(x, power = 2):\n",
    "    norm = x.pow(power).sum(1, keepdim=True).pow(1. / power)\n",
    "    out = x.div(norm)\n",
    "    return out\n",
    "\n",
    "def calc_loss1(view1_feature, view2_feature, view1_predict, view2_predict, labels_1, labels_2, alpha, beta, device, temperature, base_temperature, batch_size):\n",
    "    #print(labels_1.shape)\n",
    "    view1_feature = normalize(view1_feature, 2)\n",
    "    view2_feature = normalize(view2_feature, 2)\n",
    "    view1_predict = F.softmax(view1_predict, dim = 1)\n",
    "    view2_predict = F.softmax(view2_predict, dim = 1)\n",
    "    #term3 = ((view1_feature - view2_feature) ** 2).sum(1).sqrt().mean()\n",
    "    labels_1_ori = labels_1.float()\n",
    "    labels_2_ori = labels_2.float()\n",
    "\n",
    "    labels_1 = torch.argmax(labels_1, dim = 1)\n",
    "    labels_2 = torch.argmax(labels_2, dim = 1)\n",
    "    batch_size = labels_1.shape[0]\n",
    "    #print(labels_1.shape, labels_2.shape)\n",
    "    labels_1 = labels_1.contiguous().view(-1, 1)\n",
    "    labels_2 = labels_2.contiguous().view(-1, 1)\n",
    "\n",
    "    mask_img = torch.eq(labels_1, labels_1.T).float().to(device)\n",
    "    mask_txt = torch.eq(labels_2, labels_2.T).float().to(device)\n",
    "    mask_img2txt = torch.eq(labels_1, labels_2.T).float().to(device)\n",
    "    mask_txt2img = torch.eq(labels_2, labels_1.T).float().to(device)\n",
    "    mask_img2lab = torch.eq(labels_1, labels_1.T).float().to(device)\n",
    "    mask_txt2lab = torch.eq(labels_2, labels_2.T).float().to(device)\n",
    "    #print(\"here1\")\n",
    "\n",
    "    #print(view1_predict.shape, labels_1_ori.shape, labels_1.shape)\n",
    "    img_contrast = torch.div(\n",
    "        torch.matmul(view1_feature, view1_feature.T),\n",
    "        temperature)\n",
    "    txt_contrast = torch.div(\n",
    "        torch.matmul(view2_feature, view2_feature.T),\n",
    "        temperature)\n",
    "    img2txt_contrast = torch.div(\n",
    "        torch.matmul(view1_feature, view2_feature.T),\n",
    "        temperature)\n",
    "    txt2img_contrast = torch.div(\n",
    "        torch.matmul(view2_feature, view1_feature.T),\n",
    "        temperature)\n",
    "    img2lab_contrast = torch.div(\n",
    "        torch.matmul(view1_predict, labels_1_ori.T),\n",
    "        temperature)\n",
    "    txt2lab_contrast = torch.div(\n",
    "        torch.matmul(view2_predict, labels_2_ori.T),\n",
    "        temperature)\n",
    "    #print(\"here2\")\n",
    "    #print(\"img_contrast\")\n",
    "    #print(img_contrast, txt_contrast)\n",
    "    logits_img_max, _ = torch.max(img_contrast, dim=1, keepdim=True)\n",
    "    logits1 = img_contrast - logits_img_max.detach()\n",
    "    logits_txt_max, _ = torch.max(txt_contrast, dim=1, keepdim=True)\n",
    "    logits2 = txt_contrast - logits_txt_max.detach()\n",
    "    logits_img2txt_max, _ = torch.max(img2txt_contrast, dim=1, keepdim=True)\n",
    "    logits3 = img2txt_contrast - logits_img2txt_max.detach()\n",
    "    logits_txt2img_max, _ = torch.max(txt2img_contrast, dim=1, keepdim=True)\n",
    "    logits4 = txt2img_contrast - logits_txt2img_max.detach()\n",
    "    logits_img2lab_max, _ = torch.max(img2lab_contrast, dim=1, keepdim=True)\n",
    "    logits5 = img2lab_contrast - logits_img2lab_max.detach()\n",
    "    logits_txt2lab_max, _ = torch.max(txt2lab_contrast, dim=1, keepdim=True)\n",
    "    logits6 = txt2lab_contrast - logits_txt2lab_max.detach()\n",
    "    #print(\"here3\")\n",
    "    contrast_count = 1\n",
    "    anchor_count = 1\n",
    "    # tile mask\n",
    "    mask_img = mask_img.repeat(anchor_count, contrast_count)\n",
    "    mask_txt = mask_txt.repeat(anchor_count, contrast_count)\n",
    "    mask_img2txt = mask_img2txt.repeat(anchor_count, contrast_count)\n",
    "    mask_txt2img = mask_txt2img.repeat(anchor_count, contrast_count)\n",
    "    mask_img2lab = mask_img2lab.repeat(anchor_count, contrast_count)\n",
    "    mask_txt2lab = mask_txt2lab.repeat(anchor_count, contrast_count)\n",
    "    #print(mask_img.shape,view1_feature.shape[1])\n",
    "    #print(mask_img)\n",
    "    logits_mask_1 = torch.scatter(\n",
    "        torch.ones_like(mask_img),\n",
    "        1,\n",
    "        torch.arange(batch_size * anchor_count).view(-1, 1).to(device),\n",
    "        0\n",
    "    )\n",
    "    logits_mask_2 = torch.scatter(\n",
    "        torch.ones_like(mask_txt),\n",
    "        1,\n",
    "        torch.arange(batch_size * anchor_count).view(-1, 1).to(device),\n",
    "        0\n",
    "    )\n",
    "    logits_mask_3 = torch.scatter(\n",
    "        torch.ones_like(mask_img2txt),\n",
    "        1,\n",
    "        torch.arange(batch_size * anchor_count).view(-1, 1).to(device),\n",
    "        0\n",
    "    )\n",
    "    logits_mask_4 = torch.scatter(\n",
    "        torch.ones_like(mask_txt2img),\n",
    "        1,\n",
    "        torch.arange(batch_size * anchor_count).view(-1, 1).to(device),\n",
    "        0\n",
    "    )\n",
    "    logits_mask_5 = torch.scatter(\n",
    "        torch.ones_like(mask_img),\n",
    "        1,\n",
    "        torch.arange(batch_size * anchor_count).view(-1, 1).to(device),\n",
    "        0\n",
    "    )\n",
    "    logits_mask_6 = torch.scatter(\n",
    "        torch.ones_like(mask_txt),\n",
    "        1,\n",
    "        torch.arange(batch_size * anchor_count).view(-1, 1).to(device),\n",
    "        0\n",
    "    )\n",
    "    #print(\"here4\")\n",
    "    mask_img = mask_img * logits_mask_1\n",
    "    mask_txt = mask_txt * logits_mask_2\n",
    "    mask_img2txt = mask_img2txt * logits_mask_3\n",
    "    mask_txt2img = mask_txt2img * logits_mask_4\n",
    "    mask_img2lab = mask_img2lab * logits_mask_5\n",
    "    mask_txt2lab = mask_txt2lab * logits_mask_6\n",
    "    # compute log_prob\n",
    "    exp_logits1 = torch.exp(logits1) * logits_mask_1\n",
    "    exp_logits2 = torch.exp(logits2) * logits_mask_2\n",
    "    exp_logits3 = torch.exp(logits3) * logits_mask_3\n",
    "    exp_logits4 = torch.exp(logits4) * logits_mask_4\n",
    "    exp_logits5 = torch.exp(logits5) * logits_mask_5\n",
    "    exp_logits6 = torch.exp(logits6) * logits_mask_6\n",
    "    #print(\"exp_logits1\")\n",
    "    #print(exp_logits1,exp_logits2)\n",
    "    log_prob1 = logits1 - torch.log(exp_logits1.sum(1, keepdim=True))\n",
    "    log_prob2 = logits2 - torch.log(exp_logits2.sum(1, keepdim=True))\n",
    "    log_prob3 = logits3 - torch.log(exp_logits3.sum(1, keepdim=True))\n",
    "    log_prob4 = logits4 - torch.log(exp_logits4.sum(1, keepdim=True))\n",
    "    log_prob5 = logits5 - torch.log(exp_logits5.sum(1, keepdim=True))\n",
    "    log_prob6 = logits6 - torch.log(exp_logits6.sum(1, keepdim=True))\n",
    "    #print(\"log_prob3\")\n",
    "    #print(log_prob3,log_prob3)\n",
    "    # compute mean of log-likelihood over positive\n",
    "    mean_log_prob_pos1 = (mask_img * log_prob1).sum(1) / mask_img.sum(1)\n",
    "    mean_log_prob_pos2 = (mask_txt * log_prob2).sum(1) / mask_txt.sum(1)\n",
    "    mean_log_prob_pos3 = (mask_img2txt * log_prob3).sum(1) / mask_img2txt.sum(1)\n",
    "    mean_log_prob_pos4 = (mask_txt2img * log_prob4).sum(1) / mask_txt2img.sum(1)\n",
    "    mean_log_prob_pos5 = (mask_img2lab * log_prob5).sum(1) / mask_img2lab.sum(1)\n",
    "    mean_log_prob_pos6 = (mask_txt2lab * log_prob6).sum(1) / mask_txt2lab.sum(1)\n",
    "    #print(\"mean_log_prob_pos1\")\n",
    "    #print(mean_log_prob_pos1)\n",
    "    # loss\n",
    "    loss1 = - (temperature / base_temperature) * mean_log_prob_pos1\n",
    "    loss2 = - (temperature / base_temperature) * mean_log_prob_pos2\n",
    "    loss3 = - (temperature / base_temperature) * mean_log_prob_pos3\n",
    "    loss4 = - (temperature / base_temperature) * mean_log_prob_pos4\n",
    "    loss5 = - (temperature / base_temperature) * mean_log_prob_pos5\n",
    "    loss6 = - (temperature / base_temperature) * mean_log_prob_pos6\n",
    "    #print(\"loss1\")\n",
    "    #print(loss1)\n",
    "    loss1 = loss1.view(1, batch_size).mean()\n",
    "    loss2 = loss2.view(1, batch_size).mean()\n",
    "    loss3 = loss3.view(1, batch_size).mean()\n",
    "    loss4 = loss4.view(1, batch_size).mean()\n",
    "    loss5 = loss5.view(1, batch_size).mean()\n",
    "    loss6 = loss6.view(1, batch_size).mean()\n",
    "    #print(\"loss1\")\n",
    "    #print(loss1)\n",
    "    return loss3 + loss4 + loss1 + loss2 + loss5 + loss6\n",
    "\n",
    "def calc_loss2(view1_feature, view2_feature, view1_predict, view2_predict, labels_1, labels_2, alpha, beta, device, temperature, base_temperature, batch_size):\n",
    "    #print(labels_1.shape)\n",
    "    view1_feature = normalize(view1_feature, 2)\n",
    "    view2_feature = normalize(view2_feature, 2)\n",
    "    #print(\"view1_feature, view2_feature\")\n",
    "    #print(view1_feature, view2_feature)\n",
    "   \n",
    "    img2txt_contrast = torch.div(\n",
    "        torch.matmul(view1_feature, view2_feature.T),\n",
    "        temperature)\n",
    "    txt2img_contrast = torch.div(\n",
    "        torch.matmul(view2_feature, view1_feature.T),\n",
    "        temperature)\n",
    "    #print(\"img2txt_contrast, txt2img_contrast\")\n",
    "    #print(img2txt_contrast, txt2img_contrast)\n",
    "    logits_img2txt_max, _ = torch.max(img2txt_contrast, dim=1, keepdim=True)\n",
    "    logits3 = img2txt_contrast - logits_img2txt_max.detach()\n",
    "    logits_txt2img_max, _ = torch.max(txt2img_contrast, dim=1, keepdim=True)\n",
    "    logits4 = txt2img_contrast - logits_txt2img_max.detach()\n",
    "    #print(\"logits3, logits4\")\n",
    "    #print(logits3, logits4)\n",
    "   \n",
    "    exp_logits3 = torch.exp(logits3)\n",
    "    exp_logits4 = torch.exp(logits4)\n",
    "    #print(\"exp_logits1\")\n",
    "    #print(exp_logits3, exp_logits4)\n",
    "    log_prob3 = logits3 - torch.log(exp_logits3.sum(1, keepdim=True))\n",
    "    log_prob4 = logits4 - torch.log(exp_logits4.sum(1, keepdim=True))\n",
    "    #print(\"log_prob3\")\n",
    "    #print(log_prob3,log_prob3)\n",
    "    # compute mean of log-likelihood over positive\n",
    "    mask_img2txt = torch.eye(logits3.shape[0], m=logits3.shape[1], out=None).to(device)\n",
    "    mask_txt2img = torch.eye(logits4.shape[0], m=logits4.shape[1], out=None).to(device)\n",
    "    mean_log_prob_pos3 = (mask_img2txt * log_prob3).sum(1) / mask_img2txt.sum(1)\n",
    "    mean_log_prob_pos4 = (mask_txt2img * log_prob4).sum(1) / mask_txt2img.sum(1)\n",
    "    #print(\"mean_log_prob_pos1\")\n",
    "    #print(mean_log_prob_pos1)\n",
    "    # loss\n",
    "    loss3 = - (temperature / base_temperature) * mean_log_prob_pos3\n",
    "    loss4 = - (temperature / base_temperature) * mean_log_prob_pos4\n",
    "    #print(\"loss1\")\n",
    "    #print(loss1)\n",
    "    loss3 = loss3.view(1, logits3.shape[0]).mean()\n",
    "    loss4 = loss4.view(1, logits4.shape[0]).mean()\n",
    "    #print(\"loss3 loss4\")\n",
    "    #print(loss3, loss4)\n",
    "    return 100*(loss3 + loss4)# + (loss1 + loss2) * 0.5\n",
    "\n",
    "def train_model(model, data_loaders, optimizer, alpha, beta, device=\"cpu\", num_epochs=500):\n",
    "    since = time.time()\n",
    "    # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    batch_size = 800\n",
    "    temperature = 0.7#0.37 best now\n",
    "    base_temperature = 0.07 #0.07 best now\n",
    "    test_img_acc_history = []\n",
    "    test_txt_acc_history = []\n",
    "    epoch_loss_history =[]\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        #adjust_learning_rate(optimizer, epoch)\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 20)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                # Set model to training mode\n",
    "                model.train()\n",
    "            else:\n",
    "                # Set model to evaluate mode\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects_img = 0\n",
    "            running_corrects_txt = 0\n",
    "            # Iterate over data.\n",
    "            for idx,(imgs, txts, labels) in enumerate(data_loaders[phase]):\n",
    "                #warmup_learning_rate(epoch, idx, len(data_loaders[phase]), optimizer)\n",
    "                # imgs = imgs.to(device)\n",
    "                # txts = txts.to(device)\n",
    "                # labels = labels.to(device)\n",
    "                labels = np.squeeze(labels)\n",
    "                #print(labels.shape)\n",
    "                if torch.sum(imgs != imgs)>1 or torch.sum(txts != txts)>1:\n",
    "                    print(\"Data contains Nan.\")\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if torch.cuda.is_available():\n",
    "                        imgs = imgs.to(device)#.cuda()\n",
    "                        txts = txts.to(device)#.cuda()\n",
    "                        labels = labels.to(device)#.cuda()\n",
    "\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # Forward\n",
    "                    view1_feature, view2_feature, view1_predict, view2_predict = model(imgs, txts)\n",
    "\n",
    "                    loss = calc_loss2(view1_feature, view2_feature, view1_predict, view2_predict, labels, labels, alpha, beta, device, temperature, base_temperature, batch_size)\n",
    "\n",
    "                    img_preds = view1_predict\n",
    "                    txt_preds = view2_predict\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item()\n",
    "                running_corrects_img += torch.sum(torch.argmax(img_preds, dim=1) == labels)#torch.argmax(labels, dim=1))\n",
    "                running_corrects_txt += torch.sum(torch.argmax(txt_preds, dim=1) == labels)#torch.argmax(labels, dim=1))\n",
    "\n",
    "            epoch_loss = running_loss / len(data_loaders[phase].dataset)\n",
    "            # epoch_img_acc = running_corrects_img.double() / len(data_loaders[phase].dataset)\n",
    "            # epoch_txt_acc = running_corrects_txt.double() / len(data_loaders[phase].dataset)\n",
    "            t_imgs, t_txts, t_labels = [], [], []\n",
    "            with torch.no_grad():\n",
    "                for imgs, txts, labels in data_loaders['test']:\n",
    "                    #print(\"test: \", labels.shape)\n",
    "                    #labels = np.squeeze(labels)\n",
    "                    if torch.cuda.is_available():\n",
    "                        imgs = imgs.cuda()\n",
    "                        txts = txts.cuda()\n",
    "                        labels = labels.cuda()\n",
    "                    t_view1_feature, t_view2_feature, _, _ = model(imgs, txts)\n",
    "                    t_view1_feature, t_view2_feature = normalize(t_view1_feature, 2), normalize(t_view2_feature, 2)\n",
    "                    temp = labels.cpu().numpy()\n",
    "                    #print(\"temp shape: \", temp.shape)\n",
    "                    t_imgs.append(t_view1_feature.cpu().numpy())\n",
    "                    t_txts.append(t_view2_feature.cpu().numpy())\n",
    "                    t_labels.extend(temp)\n",
    "                    #print(\"t_labels in loop:\", len(t_labels))\n",
    "            t_imgs = np.concatenate(t_imgs)\n",
    "            t_txts = np.concatenate(t_txts)\n",
    "            #print(\"t_labels value:\", t_labels)\n",
    "            #print(\"t_labels:\" , np.array(t_labels, dtype = int).shape)\n",
    "            #t_labels = np.concatenate(t_labels).argmax(1)\n",
    "            if epoch < 500:\n",
    "                img2text = fx_calc_map_label(t_imgs, t_txts, t_labels, dist_method='COS')\n",
    "                txt2img = fx_calc_map_label(t_txts, t_imgs, t_labels, dist_method='COS')\n",
    "            else:\n",
    "                img2text = fx_calc_map_label(t_imgs, t_txts, t_labels, dist_method='COS')\n",
    "                txt2img = fx_calc_map_label(t_txts, t_imgs, t_labels, dist_method='COS')\n",
    "\n",
    "            #print(\"img2text: r1, r5, r10\", img2text[0], img2text[1], img2text[2])\n",
    "            #print(\"txt2img: r1, r5, r10\", txt2img[0], txt2img[1], txt2img[2])\n",
    "            #print(\"average: r1, r5, r10\", (txt2img[0]+img2text[0]) / 2, (txt2img[1] + img2text[1]) / 2, (txt2img[2] + img2text[2]) / 2)\n",
    "            print('{} Loss: {:.4f} Img2Txt: {:.4f}  Txt2Img: {:.4f}  Average: {:.4f}  Best_acc: {:.4f}'.format(phase, epoch_loss, img2text, txt2img, (img2text + txt2img) / 2, best_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'test' and (img2text + txt2img) / 2. > best_acc:\n",
    "                best_acc = (img2text + txt2img) / 2.\n",
    "                torch.save(model, './model_cl')\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'test':\n",
    "                test_img_acc_history.append(img2text)\n",
    "                test_txt_acc_history.append(txt2img)\n",
    "                epoch_loss_history.append(epoch_loss)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best average ACC: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, test_img_acc_history, test_txt_acc_history, epoch_loss_history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.spatial as T\n",
    "\n",
    "def fx_calc_map_label(image, text, label, k = 0, dist_method='COS'):\n",
    "  #print(\"labels:\" ,len(label))\n",
    "  #label =  np.array(label)\n",
    "  #label = np.squeeze(label)\n",
    "  #print(\"labels:\" ,len(label))\n",
    "  #print(label.shape)\n",
    "  if dist_method == 'L2':\n",
    "    dist = scipy.spatial.distance.cdist(image, text, 'euclidean')\n",
    "  elif dist_method == 'COS':\n",
    "    dist = scipy.spatial.distance.cdist(image, text, 'cosine')\n",
    "  ord = dist.argsort()\n",
    "  numcases = dist.shape[0]\n",
    "  res = []\n",
    "  for i in range(numcases):\n",
    "    order = ord[i]\n",
    "    p = 0.0\n",
    "    r = 0.0\n",
    "    for j in range(numcases):\n",
    "      #print(np.array(label).shape)\n",
    "      if label[i] == label[order[j]]:\n",
    "          res += [j]\n",
    "          break\n",
    "  rank = [1, 5, 10]\n",
    "  acc = [sum([_ < r for _ in res]) / len(res) for r in rank]\n",
    "  return acc[2]\n",
    "\n",
    "\n",
    "def fx_calc_map_label1(image, text, label, k = 0, dist_method='COS'):\n",
    "  if dist_method == 'L2':\n",
    "    dist = T.distance.cdist(image, text, 'euclidean')\n",
    "  elif dist_method == 'COS':\n",
    "    dist = T.distance.cdist(image, text, 'cosine')\n",
    "  ord = dist.argsort()\n",
    "  numcases = dist.shape[0]\n",
    "  if k == 0:\n",
    "    k = numcases\n",
    "  res = []\n",
    "  for i in range(numcases):\n",
    "    order = ord[i]\n",
    "    p = 0.0\n",
    "    r = 0.0\n",
    "    for j in range(k):\n",
    "      if label[i] == label[order[j]]:\n",
    "        r += 1\n",
    "        p += (r / (j + 1))\n",
    "    if r > 0:\n",
    "      res += [p / r]\n",
    "    else:\n",
    "      res += [0]\n",
    "  return np.mean(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Data loading is beginning...\n",
      "[[ 2772 12264 22100 ...   860 15795 23654]]\n",
      "...Data loading is completed...\n",
      "...Training is beginning...\n",
      "Epoch 1/500\n",
      "--------------------\n",
      "train Loss: 1.8371 Img2Txt: 0.0406  Txt2Img: 0.0406  Average: 0.0406  Best_acc: 0.0000\n",
      "test Loss: 9.4176 Img2Txt: 0.0406  Txt2Img: 0.0406  Average: 0.0406  Best_acc: 0.0000\n",
      "\n",
      "Epoch 2/500\n",
      "--------------------\n",
      "train Loss: 1.8217 Img2Txt: 0.0567  Txt2Img: 0.0542  Average: 0.0554  Best_acc: 0.0406\n",
      "test Loss: 9.2474 Img2Txt: 0.0567  Txt2Img: 0.0542  Average: 0.0554  Best_acc: 0.0406\n",
      "\n",
      "Epoch 3/500\n",
      "--------------------\n",
      "train Loss: 1.7962 Img2Txt: 0.0387  Txt2Img: 0.0529  Average: 0.0458  Best_acc: 0.0554\n",
      "test Loss: 9.1505 Img2Txt: 0.0387  Txt2Img: 0.0529  Average: 0.0458  Best_acc: 0.0554\n",
      "\n",
      "Epoch 4/500\n",
      "--------------------\n",
      "train Loss: 1.7786 Img2Txt: 0.0645  Txt2Img: 0.0677  Average: 0.0661  Best_acc: 0.0554\n",
      "test Loss: 9.0366 Img2Txt: 0.0645  Txt2Img: 0.0677  Average: 0.0661  Best_acc: 0.0554\n",
      "\n",
      "Epoch 5/500\n",
      "--------------------\n",
      "train Loss: 1.7640 Img2Txt: 0.0696  Txt2Img: 0.0729  Average: 0.0712  Best_acc: 0.0661\n",
      "test Loss: 8.9799 Img2Txt: 0.0696  Txt2Img: 0.0729  Average: 0.0712  Best_acc: 0.0661\n",
      "\n",
      "Epoch 6/500\n",
      "--------------------\n",
      "train Loss: 1.7558 Img2Txt: 0.0645  Txt2Img: 0.0683  Average: 0.0664  Best_acc: 0.0712\n",
      "test Loss: 8.9703 Img2Txt: 0.0645  Txt2Img: 0.0683  Average: 0.0664  Best_acc: 0.0712\n",
      "\n",
      "Epoch 7/500\n",
      "--------------------\n",
      "train Loss: 1.7552 Img2Txt: 0.0729  Txt2Img: 0.0787  Average: 0.0758  Best_acc: 0.0712\n",
      "test Loss: 8.9505 Img2Txt: 0.0729  Txt2Img: 0.0787  Average: 0.0758  Best_acc: 0.0712\n",
      "\n",
      "Epoch 8/500\n",
      "--------------------\n",
      "train Loss: 1.7468 Img2Txt: 0.0832  Txt2Img: 0.0864  Average: 0.0848  Best_acc: 0.0758\n",
      "test Loss: 8.8964 Img2Txt: 0.0832  Txt2Img: 0.0864  Average: 0.0848  Best_acc: 0.0758\n",
      "\n",
      "Epoch 9/500\n",
      "--------------------\n",
      "train Loss: 1.7408 Img2Txt: 0.0877  Txt2Img: 0.0858  Average: 0.0867  Best_acc: 0.0848\n",
      "test Loss: 8.8702 Img2Txt: 0.0877  Txt2Img: 0.0858  Average: 0.0867  Best_acc: 0.0848\n",
      "\n",
      "Epoch 10/500\n",
      "--------------------\n",
      "train Loss: 1.7369 Img2Txt: 0.0909  Txt2Img: 0.0858  Average: 0.0883  Best_acc: 0.0867\n",
      "test Loss: 8.8543 Img2Txt: 0.0909  Txt2Img: 0.0858  Average: 0.0883  Best_acc: 0.0867\n",
      "\n",
      "Epoch 11/500\n",
      "--------------------\n",
      "train Loss: 1.7340 Img2Txt: 0.0806  Txt2Img: 0.0793  Average: 0.0799  Best_acc: 0.0883\n",
      "test Loss: 8.8599 Img2Txt: 0.0806  Txt2Img: 0.0793  Average: 0.0799  Best_acc: 0.0883\n",
      "\n",
      "Epoch 12/500\n",
      "--------------------\n",
      "train Loss: 1.7364 Img2Txt: 0.0838  Txt2Img: 0.0909  Average: 0.0874  Best_acc: 0.0883\n",
      "test Loss: 8.8513 Img2Txt: 0.0838  Txt2Img: 0.0909  Average: 0.0874  Best_acc: 0.0883\n",
      "\n",
      "Epoch 13/500\n",
      "--------------------\n",
      "train Loss: 1.7311 Img2Txt: 0.0903  Txt2Img: 0.0877  Average: 0.0890  Best_acc: 0.0883\n",
      "test Loss: 8.8253 Img2Txt: 0.0903  Txt2Img: 0.0877  Average: 0.0890  Best_acc: 0.0883\n",
      "\n",
      "Epoch 14/500\n",
      "--------------------\n",
      "train Loss: 1.7275 Img2Txt: 0.0967  Txt2Img: 0.0858  Average: 0.0912  Best_acc: 0.0890\n",
      "test Loss: 8.8103 Img2Txt: 0.0967  Txt2Img: 0.0858  Average: 0.0912  Best_acc: 0.0890\n",
      "\n",
      "Epoch 15/500\n",
      "--------------------\n",
      "train Loss: 1.7242 Img2Txt: 0.0941  Txt2Img: 0.0890  Average: 0.0916  Best_acc: 0.0912\n",
      "test Loss: 8.8009 Img2Txt: 0.0941  Txt2Img: 0.0890  Average: 0.0916  Best_acc: 0.0912\n",
      "\n",
      "Epoch 16/500\n",
      "--------------------\n",
      "train Loss: 1.7223 Img2Txt: 0.0883  Txt2Img: 0.0903  Average: 0.0893  Best_acc: 0.0916\n",
      "test Loss: 8.7960 Img2Txt: 0.0883  Txt2Img: 0.0903  Average: 0.0893  Best_acc: 0.0916\n",
      "\n",
      "Epoch 17/500\n",
      "--------------------\n",
      "train Loss: 1.7211 Img2Txt: 0.0903  Txt2Img: 0.0890  Average: 0.0896  Best_acc: 0.0916\n",
      "test Loss: 8.8069 Img2Txt: 0.0903  Txt2Img: 0.0890  Average: 0.0896  Best_acc: 0.0916\n",
      "\n",
      "Epoch 18/500\n",
      "--------------------\n",
      "train Loss: 1.7212 Img2Txt: 0.0928  Txt2Img: 0.0922  Average: 0.0925  Best_acc: 0.0916\n",
      "test Loss: 8.7820 Img2Txt: 0.0928  Txt2Img: 0.0922  Average: 0.0925  Best_acc: 0.0916\n",
      "\n",
      "Epoch 19/500\n",
      "--------------------\n",
      "train Loss: 1.7181 Img2Txt: 0.0806  Txt2Img: 0.0890  Average: 0.0848  Best_acc: 0.0925\n",
      "test Loss: 8.8123 Img2Txt: 0.0806  Txt2Img: 0.0890  Average: 0.0848  Best_acc: 0.0925\n",
      "\n",
      "Epoch 20/500\n",
      "--------------------\n",
      "train Loss: 1.7217 Img2Txt: 0.0812  Txt2Img: 0.0928  Average: 0.0870  Best_acc: 0.0925\n",
      "test Loss: 8.8020 Img2Txt: 0.0812  Txt2Img: 0.0928  Average: 0.0870  Best_acc: 0.0925\n",
      "\n",
      "Epoch 21/500\n",
      "--------------------\n",
      "train Loss: 1.7180 Img2Txt: 0.0916  Txt2Img: 0.0928  Average: 0.0922  Best_acc: 0.0925\n",
      "test Loss: 8.7722 Img2Txt: 0.0916  Txt2Img: 0.0928  Average: 0.0922  Best_acc: 0.0925\n",
      "\n",
      "Epoch 22/500\n",
      "--------------------\n",
      "train Loss: 1.7130 Img2Txt: 0.0954  Txt2Img: 0.0967  Average: 0.0961  Best_acc: 0.0925\n",
      "test Loss: 8.7675 Img2Txt: 0.0954  Txt2Img: 0.0967  Average: 0.0961  Best_acc: 0.0925\n",
      "\n",
      "Epoch 23/500\n",
      "--------------------\n",
      "train Loss: 1.7113 Img2Txt: 0.0922  Txt2Img: 0.1057  Average: 0.0990  Best_acc: 0.0961\n",
      "test Loss: 8.7576 Img2Txt: 0.0922  Txt2Img: 0.1057  Average: 0.0990  Best_acc: 0.0961\n",
      "\n",
      "Epoch 24/500\n",
      "--------------------\n",
      "train Loss: 1.7099 Img2Txt: 0.0999  Txt2Img: 0.1025  Average: 0.1012  Best_acc: 0.0990\n",
      "test Loss: 8.7682 Img2Txt: 0.0999  Txt2Img: 0.1025  Average: 0.1012  Best_acc: 0.0990\n",
      "\n",
      "Epoch 25/500\n",
      "--------------------\n",
      "train Loss: 1.7110 Img2Txt: 0.0903  Txt2Img: 0.0954  Average: 0.0928  Best_acc: 0.1012\n",
      "test Loss: 8.7780 Img2Txt: 0.0903  Txt2Img: 0.0954  Average: 0.0928  Best_acc: 0.1012\n",
      "\n",
      "Epoch 26/500\n",
      "--------------------\n",
      "train Loss: 1.7105 Img2Txt: 0.0935  Txt2Img: 0.0948  Average: 0.0941  Best_acc: 0.1012\n",
      "test Loss: 8.7558 Img2Txt: 0.0935  Txt2Img: 0.0948  Average: 0.0941  Best_acc: 0.1012\n",
      "\n",
      "Epoch 27/500\n",
      "--------------------\n",
      "train Loss: 1.7065 Img2Txt: 0.0896  Txt2Img: 0.0961  Average: 0.0928  Best_acc: 0.1012\n",
      "test Loss: 8.7636 Img2Txt: 0.0896  Txt2Img: 0.0961  Average: 0.0928  Best_acc: 0.1012\n",
      "\n",
      "Epoch 28/500\n",
      "--------------------\n",
      "train Loss: 1.7087 Img2Txt: 0.0845  Txt2Img: 0.0883  Average: 0.0864  Best_acc: 0.1012\n",
      "test Loss: 8.7665 Img2Txt: 0.0845  Txt2Img: 0.0883  Average: 0.0864  Best_acc: 0.1012\n",
      "\n",
      "Epoch 29/500\n",
      "--------------------\n",
      "train Loss: 1.7062 Img2Txt: 0.0896  Txt2Img: 0.1025  Average: 0.0961  Best_acc: 0.1012\n",
      "test Loss: 8.7585 Img2Txt: 0.0896  Txt2Img: 0.1025  Average: 0.0961  Best_acc: 0.1012\n",
      "\n",
      "Epoch 30/500\n",
      "--------------------\n",
      "train Loss: 1.7054 Img2Txt: 0.0967  Txt2Img: 0.1019  Average: 0.0993  Best_acc: 0.1012\n",
      "test Loss: 8.7479 Img2Txt: 0.0967  Txt2Img: 0.1019  Average: 0.0993  Best_acc: 0.1012\n",
      "\n",
      "Epoch 31/500\n",
      "--------------------\n",
      "train Loss: 1.7019 Img2Txt: 0.0916  Txt2Img: 0.1025  Average: 0.0970  Best_acc: 0.1012\n",
      "test Loss: 8.7392 Img2Txt: 0.0916  Txt2Img: 0.1025  Average: 0.0970  Best_acc: 0.1012\n",
      "\n",
      "Epoch 32/500\n",
      "--------------------\n",
      "train Loss: 1.7014 Img2Txt: 0.0858  Txt2Img: 0.0980  Average: 0.0919  Best_acc: 0.1012\n",
      "test Loss: 8.7735 Img2Txt: 0.0858  Txt2Img: 0.0980  Average: 0.0919  Best_acc: 0.1012\n",
      "\n",
      "Epoch 33/500\n",
      "--------------------\n",
      "train Loss: 1.7045 Img2Txt: 0.0948  Txt2Img: 0.1077  Average: 0.1012  Best_acc: 0.1012\n",
      "test Loss: 8.7374 Img2Txt: 0.0948  Txt2Img: 0.1077  Average: 0.1012  Best_acc: 0.1012\n",
      "\n",
      "Epoch 34/500\n",
      "--------------------\n",
      "train Loss: 1.7004 Img2Txt: 0.0793  Txt2Img: 0.0890  Average: 0.0841  Best_acc: 0.1012\n",
      "test Loss: 8.7577 Img2Txt: 0.0793  Txt2Img: 0.0890  Average: 0.0841  Best_acc: 0.1012\n",
      "\n",
      "Epoch 35/500\n",
      "--------------------\n",
      "train Loss: 1.6991 Img2Txt: 0.1012  Txt2Img: 0.1103  Average: 0.1057  Best_acc: 0.1012\n",
      "test Loss: 8.7269 Img2Txt: 0.1012  Txt2Img: 0.1103  Average: 0.1057  Best_acc: 0.1012\n",
      "\n",
      "Epoch 36/500\n",
      "--------------------\n",
      "train Loss: 1.6956 Img2Txt: 0.0954  Txt2Img: 0.1122  Average: 0.1038  Best_acc: 0.1057\n",
      "test Loss: 8.7293 Img2Txt: 0.0954  Txt2Img: 0.1122  Average: 0.1038  Best_acc: 0.1057\n",
      "\n",
      "Epoch 37/500\n",
      "--------------------\n",
      "train Loss: 1.6950 Img2Txt: 0.0974  Txt2Img: 0.1070  Average: 0.1022  Best_acc: 0.1057\n",
      "test Loss: 8.7331 Img2Txt: 0.0974  Txt2Img: 0.1070  Average: 0.1022  Best_acc: 0.1057\n",
      "\n",
      "Epoch 38/500\n",
      "--------------------\n",
      "train Loss: 1.6969 Img2Txt: 0.0767  Txt2Img: 0.0935  Average: 0.0851  Best_acc: 0.1057\n",
      "test Loss: 8.7836 Img2Txt: 0.0767  Txt2Img: 0.0935  Average: 0.0851  Best_acc: 0.1057\n",
      "\n",
      "Epoch 39/500\n",
      "--------------------\n",
      "train Loss: 1.6970 Img2Txt: 0.0961  Txt2Img: 0.1083  Average: 0.1022  Best_acc: 0.1057\n",
      "test Loss: 8.7419 Img2Txt: 0.0961  Txt2Img: 0.1083  Average: 0.1022  Best_acc: 0.1057\n",
      "\n",
      "Epoch 40/500\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.6942 Img2Txt: 0.0735  Txt2Img: 0.0825  Average: 0.0780  Best_acc: 0.1057\n",
      "test Loss: 8.7784 Img2Txt: 0.0735  Txt2Img: 0.0825  Average: 0.0780  Best_acc: 0.1057\n",
      "\n",
      "Epoch 41/500\n",
      "--------------------\n",
      "train Loss: 1.6985 Img2Txt: 0.0858  Txt2Img: 0.1044  Average: 0.0951  Best_acc: 0.1057\n",
      "test Loss: 8.7482 Img2Txt: 0.0858  Txt2Img: 0.1044  Average: 0.0951  Best_acc: 0.1057\n",
      "\n",
      "Epoch 42/500\n",
      "--------------------\n",
      "train Loss: 1.6923 Img2Txt: 0.0948  Txt2Img: 0.1083  Average: 0.1015  Best_acc: 0.1057\n",
      "test Loss: 8.7375 Img2Txt: 0.0948  Txt2Img: 0.1083  Average: 0.1015  Best_acc: 0.1057\n",
      "\n",
      "Epoch 43/500\n",
      "--------------------\n",
      "train Loss: 1.6932 Img2Txt: 0.0858  Txt2Img: 0.0941  Average: 0.0899  Best_acc: 0.1057\n",
      "test Loss: 8.7378 Img2Txt: 0.0858  Txt2Img: 0.0941  Average: 0.0899  Best_acc: 0.1057\n",
      "\n",
      "Epoch 44/500\n",
      "--------------------\n",
      "train Loss: 1.6892 Img2Txt: 0.0974  Txt2Img: 0.1122  Average: 0.1048  Best_acc: 0.1057\n",
      "test Loss: 8.7173 Img2Txt: 0.0974  Txt2Img: 0.1122  Average: 0.1048  Best_acc: 0.1057\n",
      "\n",
      "Epoch 45/500\n",
      "--------------------\n",
      "train Loss: 1.6867 Img2Txt: 0.1025  Txt2Img: 0.1135  Average: 0.1080  Best_acc: 0.1057\n",
      "test Loss: 8.7189 Img2Txt: 0.1025  Txt2Img: 0.1135  Average: 0.1080  Best_acc: 0.1057\n",
      "\n",
      "Epoch 46/500\n",
      "--------------------\n",
      "train Loss: 1.6865 Img2Txt: 0.0877  Txt2Img: 0.0961  Average: 0.0919  Best_acc: 0.1080\n",
      "test Loss: 8.7451 Img2Txt: 0.0877  Txt2Img: 0.0961  Average: 0.0919  Best_acc: 0.1080\n",
      "\n",
      "Epoch 47/500\n",
      "--------------------\n",
      "train Loss: 1.6919 Img2Txt: 0.0877  Txt2Img: 0.0954  Average: 0.0916  Best_acc: 0.1080\n",
      "test Loss: 8.7531 Img2Txt: 0.0877  Txt2Img: 0.0954  Average: 0.0916  Best_acc: 0.1080\n",
      "\n",
      "Epoch 48/500\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "def normalized(a, order=2 ,axis=-1 ):\n",
    "    l2 = np.atleast_1d(np.linalg.norm(a, order, axis))\n",
    "    l2[l2==0] = 1\n",
    "    return a / np.expand_dims(l2, axis)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # environmental setting: setting the following parameters based on your experimental environment.\n",
    "    #dataset = 'pascal'\n",
    "    dataset = 'flicker30k'\n",
    "    device = torch.device(\"cuda\")# if torch.cuda.is_available() else \"cpu\")\n",
    "    # data parameters\n",
    "    DATA_DIR = 'data/' + dataset + '/'\n",
    "    alpha = 1e-3\n",
    "    beta = 1e-1\n",
    "    MAX_EPOCH = 500\n",
    "    batch_size = 13000 #4096\n",
    "    # batch_size = 512\n",
    "    lr = 5e-5\n",
    "    betas = (0.5, 0.999)\n",
    "    weight_decay = 0\n",
    "\n",
    "    print('...Data loading is beginning...')\n",
    "\n",
    "    data_loader, input_data_par = get_loader(DATA_DIR, batch_size)\n",
    "\n",
    "    print('...Data loading is completed...')\n",
    "\n",
    "    model_ft = IDCM_NN(img_input_dim=input_data_par['img_dim'], text_input_dim=input_data_par['text_dim'], output_dim=input_data_par['num_class']).to(device)\n",
    "    params_to_update = list(model_ft.parameters())\n",
    "\n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer = optim.Adam(params_to_update, lr=lr, betas=betas)\n",
    "\n",
    "    print('...Training is beginning...')\n",
    "    # Train and evaluate\n",
    "    model_ft, img_acc_hist, txt_acc_hist, loss_hist = train_model(model_ft, data_loader, optimizer, alpha, beta, device, MAX_EPOCH)\n",
    "    print('...Training is completed...')\n",
    "\n",
    "    print('...Evaluation on testing data...')\n",
    "    view1_feature, view2_feature, view1_predict, view2_predict = model_ft(torch.tensor(input_data_par['img_test']).to(device), torch.tensor(input_data_par['text_test']).to(device))\n",
    "    label = torch.argmax(torch.tensor(input_data_par['label_test']), dim=1)\n",
    "    view1_feature = view1_feature.detach().cpu().numpy()\n",
    "    view2_feature = view2_feature.detach().cpu().numpy()\n",
    "    view1_predict = view1_predict.detach().cpu().numpy()\n",
    "    view2_predict = view2_predict.detach().cpu().numpy()\n",
    "    t_view1_feature, t_view2_feature = normalized(view1_feature, 2), normalize(view2_feature, 2)\n",
    "    img_to_txt = fx_calc_map_label(t_view1_feature, t_view2_feature, label)\n",
    "    print('...Image to Text MAP = {}'.format(img_to_txt))\n",
    "\n",
    "    txt_to_img = fx_calc_map_label(t_view1_feature, t_view2_feature, label)\n",
    "    print('...Text to Image MAP = {}'.format(txt_to_img))\n",
    "\n",
    "    print('...Average MAP = {}'.format(((img_to_txt + txt_to_img) / 2.)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
